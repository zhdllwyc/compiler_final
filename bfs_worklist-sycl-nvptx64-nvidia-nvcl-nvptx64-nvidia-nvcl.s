//
// Generated by LLVM NVPTX Back-End
//

.version 3.2
.target sm_20, texmode_independent
.address_size 64

	// .globl	SYCL_class_bfs_OP // -- Begin function SYCL_class_bfs_OP
                                        // @SYCL_class_bfs_OP
.entry SYCL_class_bfs_OP(
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_0,
	.param .u64 SYCL_class_bfs_OP_param_1,
	.param .u64 SYCL_class_bfs_OP_param_2,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_3,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_4,
	.param .u32 SYCL_class_bfs_OP_param_5,
	.param .u64 .ptr .shared .align 4 SYCL_class_bfs_OP_param_6,
	.param .u64 .ptr .shared .align 4 SYCL_class_bfs_OP_param_7,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_8,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_9,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_10,
	.param .u64 .ptr .global .align 4 SYCL_class_bfs_OP_param_11
)
{
	.reg .pred 	%p<22>;
	.reg .b32 	%r<67>;
	.reg .b64 	%rd<85>;

// %bb.0:
	ld.param.u64 	%rd36, [SYCL_class_bfs_OP_param_4];
	ld.param.u64 	%rd33, [SYCL_class_bfs_OP_param_0];
	ld.param.u64 	%rd43, [SYCL_class_bfs_OP_param_1];
	mov.u32 	%r30, %ctaid.x;
	mov.u32 	%r31, %ntid.x;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r32, %r31, %r30, %r1;
	cvt.u64.u32 	%rd1, %r32;
	cvt.u64.u32 	%rd2, %r30;
	ld.global.s32 	%rd44, [%rd33];
	setp.ge.u64 	%p1, %rd1, %rd44;
	setp.gt.u64 	%p2, %rd2, %rd43;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	LBB0_27;
// %bb.1:
	ld.param.u64 	%rd34, [SYCL_class_bfs_OP_param_2];
	cvt.u64.u32 	%rd45, %r1;
	mul.lo.s64 	%rd46, %rd2, %rd34;
	add.s64 	%rd47, %rd46, %rd45;
	setp.ne.s64 	%p4, %rd47, %rd1;
	@%p4 bra 	LBB0_27;
// %bb.2:
	ld.param.u64 	%rd35, [SYCL_class_bfs_OP_param_3];
	cvt.u32.u64 	%r33, %rd2;
	or.b32  	%r34, %r1, %r33;
	setp.ne.s32 	%p5, %r34, 0;
	@%p5 bra 	LBB0_4;
// %bb.3:
	mov.u32 	%r35, 1;
	st.global.u32 	[%rd35], %r35;
	atom.global.exch.b32 	%r36, [%rd36], 0;
LBB0_4:
	ld.param.u64 	%rd40, [SYCL_class_bfs_OP_param_9];
	ld.param.u64 	%rd39, [SYCL_class_bfs_OP_param_8];
	ld.param.u64 	%rd38, [SYCL_class_bfs_OP_param_7];
	ld.param.u64 	%rd37, [SYCL_class_bfs_OP_param_6];
	setp.ne.s32 	%p6, %r1, 0;
	@%p6 bra 	LBB0_14;
// %bb.5:
	ld.param.u32 	%r29, [SYCL_class_bfs_OP_param_5];
	cvt.s64.s32 	%rd48, %r29;
	mul.lo.s64 	%rd3, %rd48, %rd34;
	setp.eq.s64 	%p7, %rd3, 0;
	@%p7 bra 	LBB0_13;
// %bb.6:
	add.s64 	%rd50, %rd3, -1;
	and.b64  	%rd4, %rd3, 7;
	setp.lt.u64 	%p8, %rd50, 7;
	mov.u32 	%r58, 0;
	mov.u64 	%rd80, 0;
	@%p8 bra 	LBB0_10;
// %bb.7:
	sub.s64 	%rd5, %rd3, %rd4;
	add.s64 	%rd79, %rd37, 16;
	mov.u64 	%rd80, 0;
	mov.u32 	%r38, 0;
LBB0_8:                                 // =>This Inner Loop Header: Depth=1
	st.shared.u32 	[%rd79+-16], %r38;
	st.shared.u32 	[%rd79+-12], %r38;
	st.shared.u32 	[%rd79+-8], %r38;
	st.shared.u32 	[%rd79+-4], %r38;
	st.shared.u32 	[%rd79], %r38;
	st.shared.u32 	[%rd79+4], %r38;
	st.shared.u32 	[%rd79+8], %r38;
	st.shared.u32 	[%rd79+12], %r38;
	add.s64 	%rd80, %rd80, 8;
	add.s64 	%rd79, %rd79, 32;
	setp.eq.s64 	%p9, %rd5, %rd80;
	@%p9 bra 	LBB0_9;
	bra.uni 	LBB0_8;
LBB0_9:
	cvt.u32.u64 	%r58, %rd80;
LBB0_10:
	setp.eq.s64 	%p10, %rd4, 0;
	@%p10 bra 	LBB0_13;
// %bb.11:
	add.s32 	%r59, %r58, 1;
	neg.s64 	%rd77, %rd4;
	mov.u32 	%r39, 0;
LBB0_12:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	shl.b64 	%rd52, %rd80, 2;
	add.s64 	%rd53, %rd37, %rd52;
	st.shared.u32 	[%rd53], %r39;
	cvt.u64.u32 	%rd80, %r59;
	add.s32 	%r59, %r59, 1;
	add.s64 	%rd77, %rd77, 1;
	setp.ne.s64 	%p11, %rd77, 0;
	@%p11 bra 	LBB0_12;
LBB0_13:
	atom.shared.exch.b32 	%r40, [%rd38], 0;
LBB0_14:
	bar.sync 	0;
	shl.b64 	%rd54, %rd1, 2;
	add.s64 	%rd55, %rd39, %rd54;
	ld.global.u32 	%r41, [%rd55];
	mul.wide.s32 	%rd56, %r41, 4;
	add.s64 	%rd18, %rd40, %rd56;
	ld.global.u32 	%r61, [%rd18];
	ld.global.u32 	%r62, [%rd18+4];
	setp.ge.s32 	%p12, %r61, %r62;
	@%p12 bra 	LBB0_19;
// %bb.15:
	ld.param.u64 	%rd42, [SYCL_class_bfs_OP_param_11];
	ld.param.u64 	%rd41, [SYCL_class_bfs_OP_param_10];
	cvt.s64.s32 	%rd17, %r41;
	cvt.s64.s32 	%rd19, %r61;
	shl.b64 	%rd57, %rd17, 2;
	add.s64 	%rd20, %rd42, %rd57;
	shl.b64 	%rd58, %rd19, 2;
	add.s64 	%rd81, %rd41, %rd58;
LBB0_16:                                // =>This Inner Loop Header: Depth=1
	ld.global.u32 	%r11, [%rd81];
	mul.wide.s32 	%rd59, %r11, 4;
	add.s64 	%rd23, %rd42, %rd59;
	ld.global.u32 	%r42, [%rd23];
	setp.ne.s32 	%p13, %r42, 0;
	@%p13 bra 	LBB0_18;
// %bb.17:                              //   in Loop: Header=BB0_16 Depth=1
	ld.global.u32 	%r43, [%rd20];
	add.s32 	%r44, %r43, 1;
	st.global.u32 	[%rd23], %r44;
	atom.shared.add.u32 	%r45, [%rd38], 1;
	mul.wide.u32 	%rd60, %r45, 4;
	add.s64 	%rd61, %rd37, %rd60;
	st.shared.u32 	[%rd61], %r11;
	mov.u32 	%r46, 0;
	st.global.u32 	[%rd35], %r46;
	ld.global.u32 	%r62, [%rd18+4];
LBB0_18:                                //   in Loop: Header=BB0_16 Depth=1
	add.s32 	%r61, %r61, 1;
	add.s64 	%rd81, %rd81, 4;
	setp.lt.s32 	%p14, %r61, %r62;
	@%p14 bra 	LBB0_16;
LBB0_19:
	setp.eq.s32 	%p15, %r1, 0;
	bar.sync 	0;
	@%p15 bra 	LBB0_20;
	bra.uni 	LBB0_27;
LBB0_20:
	atom.shared.add.u32 	%r15, [%rd38], 0;
	atom.global.add.u32 	%r16, [%rd36], %r15;
	add.s32 	%r17, %r16, %r15;
	setp.ge.u32 	%p16, %r16, %r17;
	@%p16 bra 	LBB0_27;
// %bb.21:
	add.s32 	%r18, %r15, -1;
	and.b32  	%r19, %r15, 3;
	setp.eq.s32 	%p17, %r19, 0;
	mov.u32 	%r65, %r16;
	@%p17 bra 	LBB0_24;
// %bb.22:
	mul.wide.s32 	%rd62, %r16, 4;
	add.s64 	%rd83, %rd39, %rd62;
	neg.s32 	%r63, %r19;
	mov.u64 	%rd82, %rd37;
	mov.u32 	%r65, %r16;
LBB0_23:                                // =>This Inner Loop Header: Depth=1
	.pragma "nounroll";
	ld.shared.u32 	%r47, [%rd82];
	st.global.u32 	[%rd83], %r47;
	add.s32 	%r65, %r65, 1;
	add.s64 	%rd83, %rd83, 4;
	add.s64 	%rd82, %rd82, 4;
	add.s32 	%r63, %r63, 1;
	setp.ne.s32 	%p18, %r63, 0;
	@%p18 bra 	LBB0_23;
LBB0_24:
	setp.lt.u32 	%p19, %r18, 3;
	@%p19 bra 	LBB0_27;
// %bb.25:
	neg.s32 	%r26, %r16;
	mul.wide.s32 	%rd63, %r65, 4;
	add.s64 	%rd64, %rd39, %rd63;
	add.s64 	%rd84, %rd64, 8;
	cvt.u64.u32 	%rd67, %r16;
LBB0_26:                                // =>This Inner Loop Header: Depth=1
	add.s32 	%r48, %r26, %r65;
	mul.wide.u32 	%rd65, %r48, 4;
	add.s64 	%rd66, %rd37, %rd65;
	ld.shared.u32 	%r49, [%rd66];
	st.global.u32 	[%rd84+-8], %r49;
	cvt.u64.u32 	%rd68, %r65;
	sub.s64 	%rd69, %rd68, %rd67;
	shl.b64 	%rd70, %rd69, 2;
	add.s64 	%rd71, %rd37, %rd70;
	ld.shared.u32 	%r50, [%rd71+4];
	st.global.u32 	[%rd84+-4], %r50;
	add.s32 	%r51, %r48, 2;
	mul.wide.u32 	%rd72, %r51, 4;
	add.s64 	%rd73, %rd37, %rd72;
	ld.shared.u32 	%r52, [%rd73];
	st.global.u32 	[%rd84], %r52;
	add.s32 	%r53, %r48, 3;
	mul.wide.u32 	%rd74, %r53, 4;
	add.s64 	%rd75, %rd37, %rd74;
	ld.shared.u32 	%r54, [%rd75];
	st.global.u32 	[%rd84+4], %r54;
	add.s32 	%r65, %r65, 4;
	add.s64 	%rd84, %rd84, 16;
	setp.ne.s32 	%p20, %r17, %r65;
	@%p20 bra 	LBB0_26;
LBB0_27:
	cvt.u32.u64 	%r55, %rd2;
	or.b32  	%r56, %r1, %r55;
	setp.ne.s32 	%p21, %r56, 0;
	@%p21 bra 	LBB0_29;
// %bb.28:
	atom.global.add.u32 	%r57, [%rd36], 0;
	st.global.u32 	[%rd33], %r57;
LBB0_29:
	ret;
                                        // -- End function
}

